# signbridge
AI-powered open-source communication app that helps non-verbal autistic children express themselves through gesture recognition and personalized suggestions.

SignBridge is an open-source assistive communication app designed for children on the autism spectrum, especially those who are non-verbal. Using AI-powered gesture recognition, personalization, and context-aware suggestions, SignBridge bridges the gap between sign-based communication and real-world needs.

When a child performs a gesture (e.g., â€œMoreâ€), the system interprets it, retrieves relevant options (e.g., more water, more juice, more playtime), and presents them visually or via text-to-speech. Over time, the app learns the childâ€™s preferences (favorite foods, activities, routines) and tailors responses accordingly.

Built with open-source AI frameworks, SignBridge is:

ğŸ¥ Gesture-aware (MediaPipe/YOLO/OpenPose)

ğŸ§  Contextual & Adaptive (RAG with FAISS/Qdrant + Embeddings)

ğŸ—£ï¸ Accessible (React Native mobile app + TTS output)

ğŸ”“ Free & Open-source (runs fully offline for privacy)

Our mission is to empower children with autism and their families by providing a cost-free, intelligent, and customizable communication tool.

Flow Summary (RAG-enabled)

Gesture Capture: Camera â†’ landmarks â†’ Gesture Agent â†’ embedding.

Intent Mapping: Embedding + context â†’ Intent Agent â†’ intent vector.

RAG Retrieval: Query vector â†’ Retriever â†’ VectorStore â†’ top-K relevant favorites/notes.

Generation: LLM Generator produces natural-language suggestion.

Output: Suggestion returned to UI + TTS.

Feedback Loop: Child/caregiver choice â†’ DB & VectorStore update for personalization.